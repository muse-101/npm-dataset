# -------------------------------------------------------------
# ğŸ’¡ åµŒå…¥ Hugo Page èªªæ˜
# å¯ç›´æ¥ç”¨ iframe åµŒå…¥ä¸åŒ CSVï¼Œä¾‹å¦‚ï¼š
# <iframe src="https://npm-dataset.streamlit.app/?embed=true&csv=d01éŠ…_s1.csv" width="100%" height="900" style="border:0;" loading="lazy"></iframe>
# è‹¥è¦ç°¡åŒ–ï¼Œå¯åœ¨ Hugo æ–°å¢ shortcodeï¼šlayouts/shortcodes/streamlit.html
# å…§å®¹ï¼š<iframe src="https://npm-dataset.streamlit.app/?embed=true&csv={{ .Get \"csv\" | urlquery }}" width="100%" height="900" style="border:0;" loading="lazy"></iframe>
# ä½¿ç”¨ï¼š{{< streamlit csv="d02ç‰_s1.csv" >}}
# -------------------------------------------------------------

# === è­·çœ¼ç°è—ä¸»é¡Œï¼ˆæŸ”å’Œç°åº•ï¼‹æ·ºç°è—ä¸»è‰²ï¼‰ ===
import streamlit as st
st.markdown(
    """
    <style>
    body, .stApp {
        background-color: #F4F5F7 !important;
        color: #111827 !important;
    }
    div[data-testid="stDataFrame"] div[role="gridcell"] {
        background-color: #FAFBFD !important;
        color: #111827 !important;
        padding-top: 0.75rem !important;
        padding-bottom: 0.75rem !important;
    }
    div[data-testid="stDataFrame"] div[role="columnheader"] {
        background-color: #EEF2F7 !important;
        color: #111827 !important;
        padding-top: 0.75rem !important;
        padding-bottom: 0.75rem !important;
    }
    .stTextInput > div > div > input {
        background-color: #FFFFFF !important;
        color: #111827 !important;
    }
    .stSelectbox div[data-baseweb="select"] {
        background-color: #FFFFFF !important;
        color: #111827 !important;
    }
    .stDownloadButton button, .stButton button {
        background-color: #5A7BD8 !important; /* æ”¹ç‚ºæ·ºç°è— */
        color: white !important;
        border: none !important;
    }
    .stDownloadButton button:hover, .stButton button:hover {
        background-color: #7395EB !important; /* hover æ›´äº® */
        color: white !important;
    }
    .stExpander, .stSelectbox, .stTextInput, .stMultiSelect, .stDataFrame {
        border-radius: 10px !important;
        box-shadow: 0 1px 4px rgba(0,0,0,0.1);
    }
    </style>
    """,
    unsafe_allow_html=True
)

# streamlit_app.py â€”â€” å›ºå®šè®€åŒå±¤ CSVã€ç„¡å´æ¬„ã€æ”¯æ´é€£çµèˆ‡ç¸®åœ–ã€ä¸‹æ‹‰åˆ†é 
import os
import math
import duckdb
import pandas as pd
import streamlit as st

st.set_page_config(page_title="CSV å…¸è—è³‡æ–™ç€è¦½å™¨", layout="wide")
st.title("CSV å…¸è—è³‡æ–™ç€è¦½å™¨")

# â€”â€” æœ¬æ©Ÿå¿«é€Ÿåˆ‡æ›æ¸¬è©¦æª”ï¼ˆåƒ…ä¿ç•™å¿«é€Ÿé€£çµï¼‰â€”â€”
TEST_FILES = [
    "d01éŠ…_s1.csv", "d02ç‰_s1.csv", "d03ç“·_s1.csv", "d04çº_s1.csv", "d05é›œ_s1.csv",
    "d06æ–‡_s1.csv", "d07ç¹”_s1.csv", "d08é›•_s1.csv", "d09æ¼†_s1.csv", "d10éŒ¢_s1.csv",
    "d20ç•«_s1.csv", "d21æ›¸_s1.csv", "d22å¸–_s1.csv", "d23æ‰‡_s1.csv", "d24çµ²_s1.csv"
]
import urllib.parse as _u

with st.expander("åˆ‡æ›æ¸¬è©¦æª”", expanded=True):
    # åƒ…é¡¯ç¤ºå¯é»é€£çµï¼ˆå·² URL encodeï¼‰
    links = "ã€€".join(f"[{name}](?csv={_u.quote(name)})" for name in TEST_FILES)
    st.markdown("å¿«é€Ÿé€£çµï¼š" + links, unsafe_allow_html=True)

# === å›ºå®šè®€åŒå±¤ CSV ===
CSV_NAME = "d01éŠ…_s1.csv"
IMAGE_COL_OVERRIDE = "imageUrl_s"
CSV_PATH = os.path.join(os.path.dirname(__file__), CSV_NAME)

# DuckDBï¼šä»¥ scan æ–¹å¼è®€å–ï¼Œä¸ä¸€æ¬¡è¼‰å…¥å…¨éƒ¨è¨˜æ†¶é«”
con = duckdb.connect()
con.execute("INSTALL httpfs; LOAD httpfs;")

# â€” URL åƒæ•¸ï¼š?csv= æ”¯æ´åŒå±¤æª”åæˆ– http(s) ç›´é€£ â€”
try:
    _qp = st.query_params if hasattr(st, "query_params") else st.experimental_get_query_params()
except Exception:
    _qp = {}
_csv_param = _qp.get("csv", "")
if isinstance(_csv_param, list):
    _csv_param = _csv_param[0] if _csv_param else ""

if _csv_param:
    if str(_csv_param).lower().startswith(("http://", "https://")):
        _is_parquet = str(_csv_param).lower().endswith(".parquet")
        scan = f"parquet_scan('{_csv_param}')" if _is_parquet else f"read_csv_auto('{_csv_param}', SAMPLE_SIZE=200000)"
        source_hint = f"è³‡æ–™ä¾†æºï¼ˆURLï¼‰ï¼š{_csv_param}"
    else:
        _alt = os.path.join(os.path.dirname(__file__), _csv_param)
        if not os.path.exists(_alt):
            st.error(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„ csv æª”ï¼š{_alt}")
            st.stop()
        scan = f"read_csv_auto('{_alt}', SAMPLE_SIZE=200000)"
        source_hint = f"è³‡æ–™ä¾†æºï¼ˆåŒå±¤æª”æ¡ˆï¼‰ï¼š{_alt}"
else:
    scan = f"read_csv_auto('{CSV_PATH}', SAMPLE_SIZE=200000)"
    source_hint = f"è³‡æ–™ä¾†æºï¼š{CSV_PATH}"

# å…ˆæŠ“æ¬„ä½
try:
    preview = con.execute(f"SELECT * FROM {scan} LIMIT 1").fetchdf()
except Exception as e:
    st.error(f"è®€å–è³‡æ–™çµæ§‹å¤±æ•—ï¼š{e}")
    st.stop()

cols = preview.columns.tolist()
if not cols:
    st.error("CSV æ²’æœ‰æ¬„ä½ã€‚")
    st.stop()

# === ä¸Šæ–¹æ§åˆ¶åˆ—ï¼šæ¬„ä½ã€æœå°‹ã€æ¯é ç­†æ•¸ï¼ˆä¸‹æ‹‰ï¼‰ ===
with st.expander("æ¬„ä½èˆ‡æœå°‹", expanded=True):
    show_cols = st.multiselect("é¡¯ç¤ºæ¬„ä½", cols, default=cols[: min(10, len(cols))])
    kw_cols   = st.multiselect("é—œéµå­—æœå°‹æ¬„ä½", cols, default=show_cols or cols)
    keyword   = st.text_input("é—œéµå­—ï¼ˆILIKE æ¨¡ç³Šæœå°‹ï¼‰", "")
    page_size = st.selectbox("æ¯é ç­†æ•¸", [25, 50, 100, 200, 500], index=2)

# WHERE æ¢ä»¶
where = "TRUE"
params = {}
if keyword and kw_cols:
    like_parts = [f'CAST("{c}" AS TEXT) ILIKE $kw' for c in kw_cols]
    where = "(" + " OR ".join(like_parts) + ")"
    params["kw"] = f"%{keyword}%"

# å…ˆç®—ç¸½ç­†æ•¸ï¼Œå†çµ¦é ç¢¼ä¸‹æ‹‰
total = con.execute(f"SELECT COUNT(*) FROM {scan} WHERE {where}", params).fetchone()[0]
total_pages = max(1, math.ceil(total / page_size))

if "page" not in st.session_state or st.session_state.page < 1 or st.session_state.page > total_pages:
    st.session_state.page = 1

b1, b2, b3, b4 = st.columns(4)
with b1:
    if st.button("â® ç¬¬ä¸€é "):
        st.session_state.page = 1
with b2:
    if st.button("â—€ ä¸Šä¸€é ") and st.session_state.page > 1:
        st.session_state.page -= 1
with b3:
    if st.button("ä¸‹ä¸€é  â–¶") and st.session_state.page < total_pages:
        st.session_state.page += 1
with b4:
    if st.button("æœ€å¾Œä¸€é  â­"):
        st.session_state.page = total_pages

page = st.session_state.page
st.caption(f"ç¬¬ {page} / {total_pages} é ")

# æŸ¥è©¢ç•¶é è³‡æ–™
offset = (page - 1) * page_size
select_cols = ", ".join([f'"{c}"' for c in (show_cols or cols)])

q = f"""
    SELECT {select_cols}
    FROM {scan}
    WHERE {where}
    LIMIT {int(page_size)} OFFSET {int(offset)}
"""
df = con.execute(q, params).fetchdf()

st.write(f"ç¬¦åˆæ¢ä»¶ï¼š{total:,} ç­†ï¼›ç¬¬ {page} / {total_pages} é ")

# === è‡ªå‹•è¾¨è­˜é€£çµæ¬„ï¼åœ–ç‰‡æ¬„ ===
def find_col(df, candidates):
    cands = {c.lower() for c in candidates}
    for c in df.columns:
        if c.lower() in cands:
            return c
    return None

link_col  = find_col(df, {"url", "link", "api_link", "href"})
image_col = IMAGE_COL_OVERRIDE if IMAGE_COL_OVERRIDE and IMAGE_COL_OVERRIDE in df.columns else \
    find_col(df, {"imageurl","image_url","imageurl_s","thumb","thumbnail","img","image"})

col_cfg = {}
if link_col:
    col_cfg[link_col] = st.column_config.LinkColumn(label=link_col, display_text="é–‹å•Ÿé€£çµ")
if image_col:
    col_cfg[image_col] = st.column_config.ImageColumn(label=image_col, help="ç¸®åœ–é è¦½")

st.data_editor(df, column_config=col_cfg, use_container_width=True, hide_index=True, disabled=True)

# ä¸‹è¼‰å€
c1, c2 = st.columns(2)
with c1:
    st.caption("ä¸‹è¼‰ç•¶é  CSV")
    st.download_button("ä¸‹è¼‰ç•¶é ", df.to_csv(index=False).encode("utf-8"), "page.csv", "text/csv")
with c2:
    st.caption("ä¸‹è¼‰å®Œæ•´ç¯©é¸ CSV")
    if st.button("ç”¢ç”Ÿå®Œæ•´ CSV"):
        out = "/tmp/filtered.csv"
        con.execute(f"COPY (SELECT {select_cols} FROM {scan} WHERE {where}) TO '{out}' (HEADER, DELIMITER ',')", params)
        with open(out, "rb") as f:
            st.download_button("ä¸‹è¼‰å®Œæ•´çµæœ", f, "filtered.csv", "text/csv")

st.divider()
st.caption(source_hint)
